{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72a257b7",
   "metadata": {},
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6daf2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import DataLoader,TensorDataset\n",
    "from torch import optim,nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from torchmetrics import Accuracy\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f6ff7c",
   "metadata": {},
   "source": [
    "# Call Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edf5cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train_test_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4705c515",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3c1eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03946cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e882a75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a2cdd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c18903f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb505fc",
   "metadata": {},
   "source": [
    "# Determination of x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be3a442",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = df.iloc[: , 4:]\n",
    "y1 = df.iloc[: , :4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed002f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7cfedb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5f12b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x1.values\n",
    "y = y1.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb1c269",
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd15633",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79bd2574",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.FloatTensor(x)\n",
    "y = torch.FloatTensor(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44bd95cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train , x_test , y_train , y_test = train_test_split(x , y , test_size = 0.2 , random_state = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4cf4704",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = torch.mean(x_train , dim = 0)\n",
    "std = torch.std(x_train , dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d091f439",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497e4d35",
   "metadata": {},
   "source": [
    "# Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b3ea0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = (x_train - mu) / std\n",
    "x_test = (x_test - mu) / std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f638f425",
   "metadata": {},
   "source": [
    "# Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad22d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = TensorDataset(x_train , y_train)\n",
    "test_set = TensorDataset(x_test , y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb01eb5b",
   "metadata": {},
   "source": [
    "# Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bf1f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=32, shuffle=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e778f5",
   "metadata": {},
   "source": [
    "# Model CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a35e8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    # First layer\n",
    "    nn.Conv1d(1, 64, kernel_size=7, stride=2, padding=3),\n",
    "    nn.BatchNorm1d(64),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool1d(kernel_size=3, stride=2, padding=1),\n",
    "\n",
    "    # layer 1\n",
    "    nn.Conv1d(64, 64, kernel_size=3, padding=1),\n",
    "    nn.BatchNorm1d(64),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv1d(64, 64, kernel_size=3, padding=1),\n",
    "    nn.BatchNorm1d(64),\n",
    "\n",
    "    # layer 2\n",
    "    nn.Conv1d(64, 128, kernel_size=3, stride=2, padding=1),\n",
    "    nn.BatchNorm1d(128),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv1d(128, 128, kernel_size=3, padding=1),\n",
    "    nn.BatchNorm1d(128),\n",
    "    nn.Conv1d(128, 128, kernel_size=1, stride=2),  # Shortcut (corrected)\n",
    "\n",
    "    # layer 3\n",
    "    nn.Conv1d(128, 256, kernel_size=3, stride=2, padding=1),\n",
    "    nn.BatchNorm1d(256),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv1d(256, 256, kernel_size=3, padding=1),\n",
    "    nn.BatchNorm1d(256),\n",
    "    nn.Conv1d(256, 256, kernel_size=1, stride=2),  # Shortcut (corrected)\n",
    "\n",
    "    # layer 4\n",
    "    nn.Conv1d(256, 512, kernel_size=3, stride=2, padding=1),\n",
    "    nn.BatchNorm1d(512),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv1d(512, 512, kernel_size=3, padding=1),\n",
    "    nn.BatchNorm1d(512),\n",
    "    nn.Conv1d(512, 512, kernel_size=1, stride=2),  # Shortcut (corrected)\n",
    "\n",
    "    # Final layer\n",
    "    nn.AdaptiveAvgPool1d(1),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(512, 4)  # خروجی 4 (تعداد خروجی‌های پیش‌بینی شده)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e132075",
   "metadata": {},
   "source": [
    "# Optimizer & Loss Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b29382f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a43efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrix\n",
    "loss_train_hist = []\n",
    "loss_test_hist = []\n",
    "\n",
    "acc_train_hist = []\n",
    "acc_test_hist = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90f795c",
   "metadata": {},
   "source": [
    "# Train & Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acaa9d4-addb-4a5a-83b2-a54a8fb159dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 80\n",
    "for num in range(num_epochs):\n",
    "    model.train()  # مدل را در حالت آموزش قرار می‌دهیم\n",
    "    train_loss = 0\n",
    "    for x_batch , y_batch in train_loader:\n",
    "        # ورودی‌ها به فرمت (batch_size, channels, length) هستند\n",
    "        x_batch = x_batch.unsqueeze(1)  # افزودن بعد کانال (در اینجا 1 کانال)\n",
    "        \n",
    "        # انجام پیش‌بینی\n",
    "        y_pre = model(x_batch)\n",
    "        \n",
    "        # محاسبه loss\n",
    "        loss = loss_fn(y_pre, y_batch)\n",
    "        \n",
    "        # بهینه‌سازی\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        loss_train_hist.append(train_loss / len(train_loader))\n",
    "\n",
    "    print(f\"Epoch [{num+1}/{num_epochs}], Train Loss: {train_loss/len(train_loader)}\")\n",
    "\n",
    "    # تست مدل\n",
    "    model.eval()  # مدل را در حالت ارزیابی قرار می‌دهیم\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():  # بدون محاسبه گرادیان\n",
    "        for x_batch1, y_batch1 in test_loader:\n",
    "            x_batch1 = x_batch1.unsqueeze(1)  # افزودن بعد کانال (در اینجا 1 کانال)\n",
    "\n",
    "            # پیش‌بینی\n",
    "            y_pre1 = model(x_batch1)\n",
    "\n",
    "            # محاسبه loss\n",
    "            loss = loss_fn(y_pre1, y_batch1)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            loss_test_hist.append(test_loss / len(test_loader))\n",
    "\n",
    "        print(f\"Epoch [{num+1}/{num_epochs}], Test Loss: {test_loss/len(test_loader)}\")\n",
    "        print(' ------------------------------------------------------------- ')\n",
    "\n",
    "print(f\"Test Loss: {test_loss/len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec38df25",
   "metadata": {},
   "source": [
    "# Plot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706ecbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# z = x[1:2 , 4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1371abbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('n2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ec90ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b2f5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = torch.FloatTensor(df2)\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ba876e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da03e121",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = torch.FloatTensor(df2) \n",
    "new_data = new_data.unsqueeze(1)  \n",
    "model.eval()  \n",
    "with torch.no_grad():  \n",
    "    predictions = model(new_data)\n",
    "\n",
    "print(\"Predictions: \", predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
